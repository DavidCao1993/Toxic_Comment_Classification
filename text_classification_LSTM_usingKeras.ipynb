{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from tqdm import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'comment_text': np.unicode,\n",
    "    \"toxic\": np.float32,\n",
    "    \"severe_toxic\": np.float32,\n",
    "    \"obscene\": np.float32,\n",
    "    \"threat\": np.float32,\n",
    "    \"insult\": np.float32,\n",
    "    \"identity_hate\": np.float32\n",
    "}\n",
    "train = pd.read_csv(\"data/train.csv\", dtype=dtypes) #, encoding='utf-8'\n",
    "test = pd.read_csv(\"data/test.csv\", dtype=dtypes) # , encoding='utf-8'\n",
    "\n",
    "train.comment_text.fillna(\"unknown\", inplace=True)\n",
    "test.comment_text.fillna(\"unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\",\n",
    "           \"identity_hate\"]\n",
    "train_data = train['comment_text']  \n",
    "labels = train[classes].values\n",
    "list_sentences_train = train[\"comment_text\"]\n",
    "list_sentences_test = test[\"comment_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## This is used to represent the corpus in the format of a  dictionary where every index represent a unique word and it is arranged from the most frequent to the least frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(list(list_sentences_train)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_features = 20000 # Number of unique words in the corpus, needs optimization\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(list_sentences_train))\n",
    "tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 153397 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %d unique tokens.' % len(word_index))\n",
    "word_count = tokenizer.word_counts\n",
    "# print('Top 5 Frequent Words count. ' % word_count[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[813, 4855, 200, 6773, 40, 7, 162, 8, 393, 234, 19, 20, 350, 14245]]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train[:1]) # Take a lot at the NN input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is done to normalize the length of the text sequences to the maxlen value\n",
    "\n",
    "    This is called [Padding], it includes shortenning the long sentences and longing the short sentences by zeros so they equal the maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 200 # needs optimization\n",
    "X = pad_sequences(tokenized_train, maxlen=maxlen)\n",
    "X_t =pad_sequences(tokenized_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nktRhOEiSOgwHSVKH4SBJ6jAcJEkd/x+cJ9x5ROE/zgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9eba9a8590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a histogram between the number of comments and the length of the comment\n",
    "totalNumWords = [len(comment) for comment in tokenized_train]\n",
    "plt.hist(totalNumWords) #, bins=np.range(0,500,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Start building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/txJomEa.png\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input is a list of encoded sentences, each sentence with a maxlen=200\n",
    "input_layer = Input(shape=(maxlen, )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2196017it [02:04, 17699.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2196016 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepaing the Embedding Layer using Glove Word Vectors\n",
    "embedding_index_glove = {}\n",
    "f = open(\"../Sentiment_Model_Template/glove.840B.300d.txt\")\n",
    "for line in tqdm(f):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embedding_index_glove[word] = coefs\n",
    "f.close()\n",
    "print('Found %s word vectors.' % len(embedding_index_glove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95851"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the data into a training set and a validation set\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "indices = np.arange(X.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "X = X[indices]\n",
    "labels = labels[indices]\n",
    "num_validation_samples = int(VALIDATION_SPLIT * X.shape[0])\n",
    "\n",
    "x_train = X[:-num_validation_samples]\n",
    "y_train = labels[:-num_validation_samples]\n",
    "x_val = X[-num_validation_samples:]\n",
    "y_val = labels[-num_validation_samples:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95851, 6)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76681, 200)\n",
      "(19170, 200)\n",
      "(76681, 6)\n",
      "(19170, 6)\n"
     ]
    }
   ],
   "source": [
    "print (x_train.shape)\n",
    "print (x_val.shape)\n",
    "print (y_train.shape)\n",
    "print (y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare embedding matrix\n",
    "EMBEDDING_DIM = 300\n",
    "num_words = min(max_features, len(word_index) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features:\n",
    "        continue\n",
    "    embedding_vector = embedding_index_glove.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = maxlen\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)(input_layer)\n",
    "\n",
    "# embedding_layer = Embedding(num_words,\n",
    "#                             EMBEDDING_DIM,\n",
    "#                             input_length=MAX_SEQUENCE_LENGTH,\n",
    "#                             trainable=False)(input_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = LSTM(units=60, return_sequences=True, name='lstm_layer')(embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = GlobalMaxPool1D()(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is done to achive Generalization, by doing some kind of regualization called [Droupout] \n",
    "    Which is basiclly done by droping the learned weights of a neuron in a NN to zero (dropout_ate=0.1) means that 10% of the neurons/nodes weights will be dropped to zero every iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Dropout(rate=0.1)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A densely connected layer anf the output passes through a ReLU functin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Dense(units=50, activation=\"relu\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Dropout(rate=0.1)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output layer has an activation [Sigmoid] to reduce the probabilities to a real number between [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Dense(units=6, activation=\"sigmoid\")(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=input_layer, outputs=x)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer= 'adam',\n",
    "              metrics= ['accuracy']) #{'toxic': 'accuracy', 'severe_toxic': 'accuracy', 'obscene': 'accuracy',\n",
    "                        #'threat': 'accuracy', 'insult': 'accuracy', 'identity_hate': 'accuracy'}) # 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76681 samples, validate on 19170 samples\n",
      "Epoch 1/10\n",
      "76681/76681 [==============================] - 358s - loss: 0.1426 - acc: 0.9634 - val_loss: 0.1447 - val_acc: 0.9621\n",
      "Epoch 2/10\n",
      "76681/76681 [==============================] - 356s - loss: 0.1422 - acc: 0.9634 - val_loss: 0.1450 - val_acc: 0.9621\n",
      "Epoch 3/10\n",
      "76681/76681 [==============================] - 362s - loss: 0.1418 - acc: 0.9634 - val_loss: 0.1450 - val_acc: 0.9621\n",
      "Epoch 4/10\n",
      "76681/76681 [==============================] - 379s - loss: 0.1408 - acc: 0.9634 - val_loss: 0.1456 - val_acc: 0.9621\n",
      "Epoch 5/10\n",
      "76681/76681 [==============================] - 376s - loss: 0.1404 - acc: 0.9634 - val_loss: 0.1463 - val_acc: 0.9621\n",
      "Epoch 6/10\n",
      "76681/76681 [==============================] - 352s - loss: 0.1405 - acc: 0.9634 - val_loss: 0.1486 - val_acc: 0.9621\n",
      "Epoch 7/10\n",
      "76681/76681 [==============================] - 349s - loss: 0.1395 - acc: 0.9634 - val_loss: 0.1463 - val_acc: 0.9621\n",
      "Epoch 8/10\n",
      "76681/76681 [==============================] - 349s - loss: 0.1387 - acc: 0.9634 - val_loss: 0.1465 - val_acc: 0.9621\n",
      "Epoch 9/10\n",
      "76681/76681 [==============================] - 370s - loss: 0.1373 - acc: 0.9634 - val_loss: 0.1480 - val_acc: 0.9621\n",
      "Epoch 10/10\n",
      "76681/76681 [==============================] - 382s - loss: 0.1356 - acc: 0.9634 - val_loss: 0.1496 - val_acc: 0.9621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9f38651c10>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      (None, 200, 300)          6000000   \n",
      "_________________________________________________________________\n",
      "lstm_layer (LSTM)            (None, 200, 60)           86640     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_6 (Glob (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 50)                3050      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 6,089,996\n",
      "Trainable params: 89,996\n",
      "Non-trainable params: 6,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226998/226998 [==============================] - 205s   \n"
     ]
    }
   ],
   "source": [
    "y_test = model.predict([X_t], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission[classes] = y_test\n",
    "sample_submission.to_csv('submissions/keras_lstm_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# A claimed improvement based on Jermey Howrad's [kernel](https://www.kaggle.com/jhoward/improved-lstm-baseline-glove-dropout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.0058384896, 0.48782218)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embs = np.stack(embedding_index_glove.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "emb_mean,emb_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare embedding matrix\n",
    "EMBEDDING_DIM = 300\n",
    "num_words = min(max_features, len(word_index) + 1)\n",
    "embedding_matrix_modified = np.random.normal(emb_mean, emb_std, (num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features:\n",
    "        continue\n",
    "    embedding_vector = embedding_index_glove.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix_modified[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(maxlen,))\n",
    "x = Embedding(max_features, EMBEDDING_DIM, weights=[embedding_matrix_modified])(inp)\n",
    "x = Bidirectional(LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(50, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(6, activation=\"sigmoid\")(x)\n",
    "model_mod = Model(inputs=inp, outputs=x)\n",
    "model_mod.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76681 samples, validate on 19170 samples\n",
      "Epoch 1/2\n",
      "76681/76681 [==============================] - 885s - loss: 0.1468 - acc: 0.9631 - val_loss: 0.1446 - val_acc: 0.9621\n",
      "Epoch 2/2\n",
      "76681/76681 [==============================] - 795s - loss: 0.1410 - acc: 0.9634 - val_loss: 0.1461 - val_acc: 0.9621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9f37352a90>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 2\n",
    "model_mod.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, \n",
    "              validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_8 (Embedding)      (None, 200, 300)          6000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 200, 100)          140400    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_7 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 6,145,756\n",
      "Trainable params: 6,145,756\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226998/226998 [==============================] - 183s   \n"
     ]
    }
   ],
   "source": [
    "y_test_mod = model.predict([X_t], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission[classes] = y_test_mod\n",
    "sample_submission.to_csv('submissions/keras_lstm_mod_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Apossible altrnative architecture\n",
    "\n",
    "# sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='float32')\n",
    "# embedded_sequences = embedding_layer(sequence_input)\n",
    "# x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "# x = MaxPooling1D(5)(x)\n",
    "# x = Conv1D(128, 5, activation='relu')(x)\n",
    "# x = MaxPooling1D(5)(x)\n",
    "# x = Conv1D(128, 5, activation='relu')(x)\n",
    "# x = MaxPooling1D(35)(x)  # global max pooling\n",
    "# x = Flatten()(x)\n",
    "# x = Dense(128, activation='relu')(x)\n",
    "# preds = Dense(len(labels_index), activation='softmax')(x)\n",
    "\n",
    "# model = Model(sequence_input, preds)\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer='rmsprop',\n",
    "#               metrics=['acc'])\n",
    "\n",
    "# # happy learning!\n",
    "# model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "#           epochs=2, batch_size=128)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
